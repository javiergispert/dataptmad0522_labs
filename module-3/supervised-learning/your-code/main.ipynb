{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries:\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will explore a dataset that describes websites with different features and labels them either benign or malicious . We will use supervised learning algorithms to figure out what feature patterns malicious websites are likely to have and use our model to predict malicious websites.\n",
    "\n",
    "# Challenge 1 - Explore The Dataset\n",
    "\n",
    "Let's start by exploring the dataset. First load the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <th>CHARSET</th>\n",
       "      <th>SERVER</th>\n",
       "      <th>CONTENT_LENGTH</th>\n",
       "      <th>WHOIS_COUNTRY</th>\n",
       "      <th>WHOIS_STATEPRO</th>\n",
       "      <th>WHOIS_REGDATE</th>\n",
       "      <th>WHOIS_UPDATED_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <th>APP_BYTES</th>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <th>REMOTE_APP_BYTES</th>\n",
       "      <th>APP_PACKETS</th>\n",
       "      <th>DNS_QUERY_TIMES</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0_109</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>iso-8859-1</td>\n",
       "      <td>nginx</td>\n",
       "      <td>263.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10/10/2015 18:21</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1153</td>\n",
       "      <td>832</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0_2314</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>Apache/2.4.10</td>\n",
       "      <td>15087.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1230</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>1265</td>\n",
       "      <td>1230</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0_911</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>us-ascii</td>\n",
       "      <td>Microsoft-HTTPAPI/2.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0_113</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "      <td>nginx</td>\n",
       "      <td>162.0</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>7/10/1997 4:00</td>\n",
       "      <td>12/09/2013 0:45</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3812</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>18784</td>\n",
       "      <td>4380</td>\n",
       "      <td>39</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0_403</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>None</td>\n",
       "      <td>124140.0</td>\n",
       "      <td>US</td>\n",
       "      <td>TX</td>\n",
       "      <td>12/05/1996 0:00</td>\n",
       "      <td>11/04/2017 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4278</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>129889</td>\n",
       "      <td>4586</td>\n",
       "      <td>61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       URL  URL_LENGTH  NUMBER_SPECIAL_CHARACTERS     CHARSET  \\\n",
       "0   M0_109          16                          7  iso-8859-1   \n",
       "1  B0_2314          16                          6       UTF-8   \n",
       "2   B0_911          16                          6    us-ascii   \n",
       "3   B0_113          17                          6  ISO-8859-1   \n",
       "4   B0_403          17                          6       UTF-8   \n",
       "\n",
       "                  SERVER  CONTENT_LENGTH WHOIS_COUNTRY WHOIS_STATEPRO  \\\n",
       "0                  nginx           263.0          None           None   \n",
       "1          Apache/2.4.10         15087.0          None           None   \n",
       "2  Microsoft-HTTPAPI/2.0           324.0          None           None   \n",
       "3                  nginx           162.0            US             AK   \n",
       "4                   None        124140.0            US             TX   \n",
       "\n",
       "      WHOIS_REGDATE WHOIS_UPDATED_DATE  ...  DIST_REMOTE_TCP_PORT  REMOTE_IPS  \\\n",
       "0  10/10/2015 18:21               None  ...                     0           2   \n",
       "1              None               None  ...                     7           4   \n",
       "2              None               None  ...                     0           0   \n",
       "3    7/10/1997 4:00    12/09/2013 0:45  ...                    22           3   \n",
       "4   12/05/1996 0:00    11/04/2017 0:00  ...                     2           5   \n",
       "\n",
       "   APP_BYTES  SOURCE_APP_PACKETS  REMOTE_APP_PACKETS  SOURCE_APP_BYTES  \\\n",
       "0        700                   9                  10              1153   \n",
       "1       1230                  17                  19              1265   \n",
       "2          0                   0                   0                 0   \n",
       "3       3812                  39                  37             18784   \n",
       "4       4278                  61                  62            129889   \n",
       "\n",
       "   REMOTE_APP_BYTES  APP_PACKETS  DNS_QUERY_TIMES  Type  \n",
       "0               832            9              2.0     1  \n",
       "1              1230           17              0.0     0  \n",
       "2                 0            0              0.0     0  \n",
       "3              4380           39              8.0     0  \n",
       "4              4586           61              4.0     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites = pd.read_csv('../data/website.csv')\n",
    "websites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the data from an bird's-eye view.\n",
    "\n",
    "You should already been very familiar with the procedures now so we won't provide the instructions step by step. Reflect on what you did in the previous labs and explore the dataset.\n",
    "\n",
    "Things you'll be looking for:\n",
    "\n",
    "* What the dataset looks like?\n",
    "* What are the data types?\n",
    "* Which columns contain the features of the websites?\n",
    "* Which column contains the feature we will predict? What is the code standing for benign vs malicious websites?\n",
    "* Do we need to transform any of the columns from categorical to ordinal values? If so what are these columns?\n",
    "\n",
    "Feel free to add additional cells for more exploration. Make sure to comment what you find!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1781 entries, 0 to 1780\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   URL                        1781 non-null   object \n",
      " 1   URL_LENGTH                 1781 non-null   int64  \n",
      " 2   NUMBER_SPECIAL_CHARACTERS  1781 non-null   int64  \n",
      " 3   CHARSET                    1781 non-null   object \n",
      " 4   SERVER                     1780 non-null   object \n",
      " 5   CONTENT_LENGTH             969 non-null    float64\n",
      " 6   WHOIS_COUNTRY              1781 non-null   object \n",
      " 7   WHOIS_STATEPRO             1781 non-null   object \n",
      " 8   WHOIS_REGDATE              1781 non-null   object \n",
      " 9   WHOIS_UPDATED_DATE         1781 non-null   object \n",
      " 10  TCP_CONVERSATION_EXCHANGE  1781 non-null   int64  \n",
      " 11  DIST_REMOTE_TCP_PORT       1781 non-null   int64  \n",
      " 12  REMOTE_IPS                 1781 non-null   int64  \n",
      " 13  APP_BYTES                  1781 non-null   int64  \n",
      " 14  SOURCE_APP_PACKETS         1781 non-null   int64  \n",
      " 15  REMOTE_APP_PACKETS         1781 non-null   int64  \n",
      " 16  SOURCE_APP_BYTES           1781 non-null   int64  \n",
      " 17  REMOTE_APP_BYTES           1781 non-null   int64  \n",
      " 18  APP_PACKETS                1781 non-null   int64  \n",
      " 19  DNS_QUERY_TIMES            1780 non-null   float64\n",
      " 20  Type                       1781 non-null   int64  \n",
      "dtypes: float64(2), int64(12), object(7)\n",
      "memory usage: 292.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "websites.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <th>CONTENT_LENGTH</th>\n",
       "      <th>TCP_CONVERSATION_EXCHANGE</th>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <th>APP_BYTES</th>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <th>REMOTE_APP_BYTES</th>\n",
       "      <th>APP_PACKETS</th>\n",
       "      <th>DNS_QUERY_TIMES</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>969.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1.781000e+03</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1.781000e+03</td>\n",
       "      <td>1.781000e+03</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1780.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.961258</td>\n",
       "      <td>11.111735</td>\n",
       "      <td>11726.927761</td>\n",
       "      <td>16.261089</td>\n",
       "      <td>5.472768</td>\n",
       "      <td>3.060640</td>\n",
       "      <td>2.982339e+03</td>\n",
       "      <td>18.540146</td>\n",
       "      <td>18.746210</td>\n",
       "      <td>1.589255e+04</td>\n",
       "      <td>3.155599e+03</td>\n",
       "      <td>18.540146</td>\n",
       "      <td>2.263483</td>\n",
       "      <td>0.121280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.555586</td>\n",
       "      <td>4.549896</td>\n",
       "      <td>36391.809051</td>\n",
       "      <td>40.500975</td>\n",
       "      <td>21.807327</td>\n",
       "      <td>3.386975</td>\n",
       "      <td>5.605057e+04</td>\n",
       "      <td>41.627173</td>\n",
       "      <td>46.397969</td>\n",
       "      <td>6.986193e+04</td>\n",
       "      <td>5.605378e+04</td>\n",
       "      <td>41.627173</td>\n",
       "      <td>2.930853</td>\n",
       "      <td>0.326544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1853.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.720000e+02</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.790000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11323.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.328000e+03</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.806000e+03</td>\n",
       "      <td>2.701000e+03</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>249.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>649263.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>708.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.362906e+06</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>1284.000000</td>\n",
       "      <td>2.060012e+06</td>\n",
       "      <td>2.362906e+06</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        URL_LENGTH  NUMBER_SPECIAL_CHARACTERS  CONTENT_LENGTH  \\\n",
       "count  1781.000000                1781.000000      969.000000   \n",
       "mean     56.961258                  11.111735    11726.927761   \n",
       "std      27.555586                   4.549896    36391.809051   \n",
       "min      16.000000                   5.000000        0.000000   \n",
       "25%      39.000000                   8.000000      324.000000   \n",
       "50%      49.000000                  10.000000     1853.000000   \n",
       "75%      68.000000                  13.000000    11323.000000   \n",
       "max     249.000000                  43.000000   649263.000000   \n",
       "\n",
       "       TCP_CONVERSATION_EXCHANGE  DIST_REMOTE_TCP_PORT   REMOTE_IPS  \\\n",
       "count                1781.000000           1781.000000  1781.000000   \n",
       "mean                   16.261089              5.472768     3.060640   \n",
       "std                    40.500975             21.807327     3.386975   \n",
       "min                     0.000000              0.000000     0.000000   \n",
       "25%                     0.000000              0.000000     0.000000   \n",
       "50%                     7.000000              0.000000     2.000000   \n",
       "75%                    22.000000              5.000000     5.000000   \n",
       "max                  1194.000000            708.000000    17.000000   \n",
       "\n",
       "          APP_BYTES  SOURCE_APP_PACKETS  REMOTE_APP_PACKETS  SOURCE_APP_BYTES  \\\n",
       "count  1.781000e+03         1781.000000         1781.000000      1.781000e+03   \n",
       "mean   2.982339e+03           18.540146           18.746210      1.589255e+04   \n",
       "std    5.605057e+04           41.627173           46.397969      6.986193e+04   \n",
       "min    0.000000e+00            0.000000            0.000000      0.000000e+00   \n",
       "25%    0.000000e+00            0.000000            0.000000      0.000000e+00   \n",
       "50%    6.720000e+02            8.000000            9.000000      5.790000e+02   \n",
       "75%    2.328000e+03           26.000000           25.000000      9.806000e+03   \n",
       "max    2.362906e+06         1198.000000         1284.000000      2.060012e+06   \n",
       "\n",
       "       REMOTE_APP_BYTES  APP_PACKETS  DNS_QUERY_TIMES         Type  \n",
       "count      1.781000e+03  1781.000000      1780.000000  1781.000000  \n",
       "mean       3.155599e+03    18.540146         2.263483     0.121280  \n",
       "std        5.605378e+04    41.627173         2.930853     0.326544  \n",
       "min        0.000000e+00     0.000000         0.000000     0.000000  \n",
       "25%        0.000000e+00     0.000000         0.000000     0.000000  \n",
       "50%        7.350000e+02     8.000000         0.000000     0.000000  \n",
       "75%        2.701000e+03    26.000000         4.000000     0.000000  \n",
       "max        2.362906e+06  1198.000000        20.000000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your comment here\n",
    "websites.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "number of uniques values: 2\n"
     ]
    }
   ],
   "source": [
    "# As we can see on the .describe() the las column 'Type' seems to be the target because it has values from 0 to 1\n",
    "\n",
    "print(websites['Type'].unique())\n",
    "print('number of uniques values:', websites['Type'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <th>CHARSET</th>\n",
       "      <th>SERVER</th>\n",
       "      <th>CONTENT_LENGTH</th>\n",
       "      <th>WHOIS_COUNTRY</th>\n",
       "      <th>WHOIS_STATEPRO</th>\n",
       "      <th>WHOIS_REGDATE</th>\n",
       "      <th>WHOIS_UPDATED_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <th>APP_BYTES</th>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <th>REMOTE_APP_BYTES</th>\n",
       "      <th>APP_PACKETS</th>\n",
       "      <th>DNS_QUERY_TIMES</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0_109</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>iso-8859-1</td>\n",
       "      <td>nginx</td>\n",
       "      <td>263.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10/10/2015 18:21</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1153</td>\n",
       "      <td>832</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M2_17</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>nginx/1.10.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8/11/2014 7:41</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>213</td>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M3_75</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>nginx/1.10.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8/11/2014 7:41</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M0_71</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "      <td>Apache/2.4.23 (Unix) OpenSSL/1.0.1e-fips mod_b...</td>\n",
       "      <td>957.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>None</td>\n",
       "      <td>16/07/2000 0:00</td>\n",
       "      <td>4/07/2015 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>717</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1960</td>\n",
       "      <td>1011</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M0_97</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>iso-8859-1</td>\n",
       "      <td>nginx</td>\n",
       "      <td>686.0</td>\n",
       "      <td>RU</td>\n",
       "      <td>Novosibirskaya obl.</td>\n",
       "      <td>25/05/2013 0:00</td>\n",
       "      <td>23/05/2016 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>603</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1580</td>\n",
       "      <td>745</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>M4_61</td>\n",
       "      <td>173</td>\n",
       "      <td>34</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>Apache</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ES</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>17/09/2008 0:00</td>\n",
       "      <td>2/09/2016 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>416</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>M4_39</td>\n",
       "      <td>178</td>\n",
       "      <td>16</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>Apache</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ES</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>17/09/2008 0:00</td>\n",
       "      <td>2/09/2016 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>M4_45</td>\n",
       "      <td>194</td>\n",
       "      <td>17</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>Apache</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ES</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>17/09/2008 0:00</td>\n",
       "      <td>2/09/2016 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>M4_48</td>\n",
       "      <td>194</td>\n",
       "      <td>16</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>Apache</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ES</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>17/09/2008 0:00</td>\n",
       "      <td>2/09/2016 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>M4_41</td>\n",
       "      <td>198</td>\n",
       "      <td>17</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>Apache</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ES</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>17/09/2008 0:00</td>\n",
       "      <td>2/09/2016 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         URL  URL_LENGTH  NUMBER_SPECIAL_CHARACTERS     CHARSET  \\\n",
       "0     M0_109          16                          7  iso-8859-1   \n",
       "8      M2_17          20                          5       utf-8   \n",
       "9      M3_75          20                          5       utf-8   \n",
       "15     M0_71          21                          7  ISO-8859-1   \n",
       "16     M0_97          21                          7  iso-8859-1   \n",
       "...      ...         ...                        ...         ...   \n",
       "1772   M4_61         173                         34       UTF-8   \n",
       "1773   M4_39         178                         16       UTF-8   \n",
       "1775   M4_45         194                         17       UTF-8   \n",
       "1776   M4_48         194                         16       UTF-8   \n",
       "1777   M4_41         198                         17       UTF-8   \n",
       "\n",
       "                                                 SERVER  CONTENT_LENGTH  \\\n",
       "0                                                 nginx           263.0   \n",
       "8                                          nginx/1.10.1             NaN   \n",
       "9                                          nginx/1.10.1             NaN   \n",
       "15    Apache/2.4.23 (Unix) OpenSSL/1.0.1e-fips mod_b...           957.0   \n",
       "16                                                nginx           686.0   \n",
       "...                                                 ...             ...   \n",
       "1772                                             Apache             NaN   \n",
       "1773                                             Apache             NaN   \n",
       "1775                                             Apache             NaN   \n",
       "1776                                             Apache             NaN   \n",
       "1777                                             Apache             NaN   \n",
       "\n",
       "     WHOIS_COUNTRY       WHOIS_STATEPRO     WHOIS_REGDATE WHOIS_UPDATED_DATE  \\\n",
       "0             None                 None  10/10/2015 18:21               None   \n",
       "8             None                 None    8/11/2014 7:41               None   \n",
       "9             None                 None    8/11/2014 7:41               None   \n",
       "15              UK                 None   16/07/2000 0:00     4/07/2015 0:00   \n",
       "16              RU  Novosibirskaya obl.   25/05/2013 0:00    23/05/2016 0:00   \n",
       "...            ...                  ...               ...                ...   \n",
       "1772            ES            Barcelona   17/09/2008 0:00     2/09/2016 0:00   \n",
       "1773            ES            Barcelona   17/09/2008 0:00     2/09/2016 0:00   \n",
       "1775            ES            Barcelona   17/09/2008 0:00     2/09/2016 0:00   \n",
       "1776            ES            Barcelona   17/09/2008 0:00     2/09/2016 0:00   \n",
       "1777            ES            Barcelona   17/09/2008 0:00     2/09/2016 0:00   \n",
       "\n",
       "      ...  DIST_REMOTE_TCP_PORT  REMOTE_IPS  APP_BYTES  SOURCE_APP_PACKETS  \\\n",
       "0     ...                     0           2        700                   9   \n",
       "8     ...                     0           0          0                   2   \n",
       "9     ...                     0           0          0                   2   \n",
       "15    ...                     0           1        717                  11   \n",
       "16    ...                     0           2        603                   8   \n",
       "...   ...                   ...         ...        ...                 ...   \n",
       "1772  ...                     1           1         90                   1   \n",
       "1773  ...                     0           0          0                   0   \n",
       "1775  ...                     0           0          0                   0   \n",
       "1776  ...                     0           0          0                   0   \n",
       "1777  ...                     0           0          0                   0   \n",
       "\n",
       "      REMOTE_APP_PACKETS  SOURCE_APP_BYTES  REMOTE_APP_BYTES  APP_PACKETS  \\\n",
       "0                     10              1153               832            9   \n",
       "8                      3               213               146            2   \n",
       "9                      1                62               146            2   \n",
       "15                    10              1960              1011           11   \n",
       "16                     9              1580               745            8   \n",
       "...                  ...               ...               ...          ...   \n",
       "1772                   5               416                90            1   \n",
       "1773                   3               186                 0            0   \n",
       "1775                   3               186                 0            0   \n",
       "1776                   3               186                 0            0   \n",
       "1777                   2               124                 0            0   \n",
       "\n",
       "      DNS_QUERY_TIMES  Type  \n",
       "0                 2.0     1  \n",
       "8                 2.0     1  \n",
       "9                 2.0     1  \n",
       "15                4.0     1  \n",
       "16                2.0     1  \n",
       "...               ...   ...  \n",
       "1772              0.0     1  \n",
       "1773              0.0     1  \n",
       "1775              0.0     1  \n",
       "1776              0.0     1  \n",
       "1777              0.0     1  \n",
       "\n",
       "[216 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Type=1 seems to be 'Malicious' and Type=0 'bening'\n",
    "\n",
    "websites[websites['Type']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL                            0\n",
       "URL_LENGTH                     0\n",
       "NUMBER_SPECIAL_CHARACTERS      0\n",
       "CHARSET                        0\n",
       "SERVER                         1\n",
       "CONTENT_LENGTH               812\n",
       "WHOIS_COUNTRY                  0\n",
       "WHOIS_STATEPRO                 0\n",
       "WHOIS_REGDATE                  0\n",
       "WHOIS_UPDATED_DATE             0\n",
       "TCP_CONVERSATION_EXCHANGE      0\n",
       "DIST_REMOTE_TCP_PORT           0\n",
       "REMOTE_IPS                     0\n",
       "APP_BYTES                      0\n",
       "SOURCE_APP_PACKETS             0\n",
       "REMOTE_APP_PACKETS             0\n",
       "SOURCE_APP_BYTES               0\n",
       "REMOTE_APP_BYTES               0\n",
       "APP_PACKETS                    0\n",
       "DNS_QUERY_TIMES                1\n",
       "Type                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_percentage(df):\n",
    "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "    missing_values_df = pd.DataFrame({'percent_missing': percent_missing})\n",
    "    return missing_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URL</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHARSET</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERVER</th>\n",
       "      <td>0.056148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONTENT_LENGTH</th>\n",
       "      <td>45.592364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHOIS_COUNTRY</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHOIS_STATEPRO</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHOIS_REGDATE</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHOIS_UPDATED_DATE</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCP_CONVERSATION_EXCHANGE</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APP_BYTES</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REMOTE_APP_BYTES</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APP_PACKETS</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNS_QUERY_TIMES</th>\n",
       "      <td>0.056148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           percent_missing\n",
       "URL                               0.000000\n",
       "URL_LENGTH                        0.000000\n",
       "NUMBER_SPECIAL_CHARACTERS         0.000000\n",
       "CHARSET                           0.000000\n",
       "SERVER                            0.056148\n",
       "CONTENT_LENGTH                   45.592364\n",
       "WHOIS_COUNTRY                     0.000000\n",
       "WHOIS_STATEPRO                    0.000000\n",
       "WHOIS_REGDATE                     0.000000\n",
       "WHOIS_UPDATED_DATE                0.000000\n",
       "TCP_CONVERSATION_EXCHANGE         0.000000\n",
       "DIST_REMOTE_TCP_PORT              0.000000\n",
       "REMOTE_IPS                        0.000000\n",
       "APP_BYTES                         0.000000\n",
       "SOURCE_APP_PACKETS                0.000000\n",
       "REMOTE_APP_PACKETS                0.000000\n",
       "SOURCE_APP_BYTES                  0.000000\n",
       "REMOTE_APP_BYTES                  0.000000\n",
       "APP_PACKETS                       0.000000\n",
       "DNS_QUERY_TIMES                   0.056148\n",
       "Type                              0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we can see we could drop the NaN value in Server and DNS_Query_Times cause its represents less than 0,1%.\n",
    "# With Content_Length we can delete the column cause it has 46% of NaN or fill it.\n",
    "\n",
    "missing_percentage(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <th>CHARSET</th>\n",
       "      <th>SERVER</th>\n",
       "      <th>CONTENT_LENGTH</th>\n",
       "      <th>WHOIS_COUNTRY</th>\n",
       "      <th>WHOIS_STATEPRO</th>\n",
       "      <th>WHOIS_REGDATE</th>\n",
       "      <th>WHOIS_UPDATED_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <th>APP_BYTES</th>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <th>REMOTE_APP_BYTES</th>\n",
       "      <th>APP_PACKETS</th>\n",
       "      <th>DNS_QUERY_TIMES</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>B0_2134</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9405.0</td>\n",
       "      <td>US</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>1/02/2003 16:44</td>\n",
       "      <td>2/02/2017 17:11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1026</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>246</td>\n",
       "      <td>1026</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          URL  URL_LENGTH  NUMBER_SPECIAL_CHARACTERS CHARSET SERVER  \\\n",
       "1306  B0_2134          66                         11   UTF-8    NaN   \n",
       "\n",
       "      CONTENT_LENGTH WHOIS_COUNTRY        WHOIS_STATEPRO    WHOIS_REGDATE  \\\n",
       "1306          9405.0            US  District of Columbia  1/02/2003 16:44   \n",
       "\n",
       "     WHOIS_UPDATED_DATE  ...  DIST_REMOTE_TCP_PORT  REMOTE_IPS  APP_BYTES  \\\n",
       "1306    2/02/2017 17:11  ...                     2           4       1026   \n",
       "\n",
       "      SOURCE_APP_PACKETS  REMOTE_APP_PACKETS  SOURCE_APP_BYTES  \\\n",
       "1306                  15                   4               246   \n",
       "\n",
       "      REMOTE_APP_BYTES  APP_PACKETS  DNS_QUERY_TIMES  Type  \n",
       "1306              1026           15              0.0     0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#websites[websites.isna().any(axis=1)]\n",
    "websites[websites['DNS_QUERY_TIMES'].isna()]\n",
    "websites[websites['SERVER'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = websites[websites['DNS_QUERY_TIMES'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = websites[websites['SERVER'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites.drop(columns='CONTENT_LENGTH', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL                          0\n",
       "URL_LENGTH                   0\n",
       "NUMBER_SPECIAL_CHARACTERS    0\n",
       "CHARSET                      0\n",
       "SERVER                       0\n",
       "WHOIS_COUNTRY                0\n",
       "WHOIS_STATEPRO               0\n",
       "WHOIS_REGDATE                0\n",
       "WHOIS_UPDATED_DATE           0\n",
       "TCP_CONVERSATION_EXCHANGE    0\n",
       "DIST_REMOTE_TCP_PORT         0\n",
       "REMOTE_IPS                   0\n",
       "APP_BYTES                    0\n",
       "SOURCE_APP_PACKETS           0\n",
       "REMOTE_APP_PACKETS           0\n",
       "SOURCE_APP_BYTES             0\n",
       "REMOTE_APP_BYTES             0\n",
       "APP_PACKETS                  0\n",
       "DNS_QUERY_TIMES              0\n",
       "Type                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming columns from categ. to ordinal (WHOIS_REGDATE & WHOIS_UPDATED_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, evaluate if the columns in this dataset are strongly correlated.\n",
    "\n",
    "In class, we discussed that we are concerned if our dataset has strongly correlated columns because if this is the case we need to choose certain ML algorithms instead of others. We need to evaluate this for our dataset now.\n",
    "\n",
    "Luckily, most of the columns in this dataset are ordinal which makes things a lot easier for us. In the cells below, evaluate the level of collinearity of the data.\n",
    "\n",
    "We provide some general directions for you to consult in order to complete this step:\n",
    "\n",
    "1. You will create a correlation matrix using the numeric columns in the dataset.\n",
    "\n",
    "1. Create a heatmap using `seaborn` to visualize which columns have high collinearity.\n",
    "\n",
    "1. Comment on which columns you might need to remove due to high collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comment here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Remove Column Collinearity.\n",
    "\n",
    "From the heatmap you created, you should have seen at least 3 columns that can be removed due to high collinearity. Remove these columns from the dataset.\n",
    "\n",
    "Note that you should remove as few columns as you can. You don't have to remove all the columns at once. But instead, try removing one column, then produce the heatmap again to determine if additional columns should be removed. As long as the dataset no longer contains columns that are correlated for over 90%, you can stop. Also, keep in mind when two columns have high collinearity, you only need to remove one of them but not both.\n",
    "\n",
    "In the cells below, remove as few columns as you can to eliminate the high collinearity in the dataset. Make sure to comment on your way so that the instructional team can learn about your thinking process which allows them to give feedback. At the end, print the heatmap again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comment here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print heatmap again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Handle Missing Values\n",
    "\n",
    "The next step would be handling missing values. **We start by examining the number of missing values in each column, which you will do in the next cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember in the previous labs, we drop a column if the column contains a high proportion of missing values. After dropping those problematic columns, we drop the rows with missing values.\n",
    "\n",
    "#### In the cells below, handle the missing values from the dataset. Remember to comment the rationale of your decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comment here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again, examine the number of missing values in each column. \n",
    "\n",
    "If all cleaned, proceed. Otherwise, go back and do more cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine missing values in each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Handle `WHOIS_*` Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several categorical columns we need to handle. These columns are:\n",
    "\n",
    "* `URL`\n",
    "* `CHARSET`\n",
    "* `SERVER`\n",
    "* `WHOIS_COUNTRY`\n",
    "* `WHOIS_STATEPRO`\n",
    "* `WHOIS_REGDATE`\n",
    "* `WHOIS_UPDATED_DATE`\n",
    "\n",
    "How to handle string columns is always case by case. Let's start by working on `WHOIS_COUNTRY`. Your steps are:\n",
    "\n",
    "1. List out the unique values of `WHOIS_COUNTRY`.\n",
    "1. Consolidate the country values with consistent country codes. For example, the following values refer to the same country and should use consistent country code:\n",
    "    * `CY` and `Cyprus`\n",
    "    * `US` and `us`\n",
    "    * `SE` and `se`\n",
    "    * `GB`, `United Kingdom`, and `[u'GB'; u'UK']`\n",
    "\n",
    "#### In the cells below, fix the country values as intructed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have fixed the country values, can we convert this column to ordinal now?\n",
    "\n",
    "Not yet. If you reflect on the previous labs how we handle categorical columns, you probably remember we ended up dropping a lot of those columns because there are too many unique values. Too many unique values in a column is not desirable in machine learning because it makes prediction inaccurate. But there are workarounds under certain conditions. One of the fixable conditions is:\n",
    "\n",
    "#### If a limited number of values account for the majority of data, we can retain these top values and re-label all other rare values.\n",
    "\n",
    "The `WHOIS_COUNTRY` column happens to be this case. You can verify it by print a bar chart of the `value_counts` in the next cell to verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After verifying, now let's keep the top 10 values of the column and re-label other columns with `OTHER`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now since `WHOIS_COUNTRY` has been re-labelled, we don't need `WHOIS_STATEPRO` any more because the values of the states or provinces may not be relevant any more. We'll drop this column.\n",
    "\n",
    "In addition, we will also drop `WHOIS_REGDATE` and `WHOIS_UPDATED_DATE`. These are the registration and update dates of the website domains. Not of our concerns.\n",
    "\n",
    "#### In the next cell, drop `['WHOIS_STATEPRO', 'WHOIS_REGDATE', 'WHOIS_UPDATED_DATE']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5 - Handle Remaining Categorical Data & Convert to Ordinal\n",
    "\n",
    "Now print the `dtypes` of the data again. Besides `WHOIS_COUNTRY` which we already fixed, there should be 3 categorical columns left: `URL`, `CHARSET`, and `SERVER`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `URL` is easy. We'll simply drop it because it has too many unique values that there's no way for us to consolidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the unique value counts of `CHARSET`. You see there are only a few unique values. So we can keep it as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SERVER` is a little more complicated. Print its unique values and think about how you can consolidate those values.\n",
    "\n",
    "#### Before you think of your own solution, don't read the instructions that come next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Think Hard](../images/think-hard.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comment here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are so many unique values in the `SERVER` column, there are actually only 3 main server types: `Microsoft`, `Apache`, and `nginx`. Just check if each `SERVER` value contains any of those server types and re-label them. For `SERVER` values that don't contain any of those substrings, label with `Other`.\n",
    "\n",
    "At the end, your `SERVER` column should only contain 4 unique values: `Microsoft`, `Apache`, `nginx`, and `Other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count `SERVER` value counts here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, all our categorical data are fixed now. **Let's convert them to ordinal data using Pandas' `get_dummies` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)).** Make sure you drop the categorical columns by passing `drop_first=True` to `get_dummies` as we don't need them any more. **Also, assign the data with dummy values to a new variable `website_dummy`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, inspect `website_dummy` to make sure the data and types are intended - there shouldn't be any categorical columns at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 6 - Modeling, Prediction, and Evaluation\n",
    "\n",
    "We'll start off this section by splitting the data to train and test. **Name your 4 variables `X_train`, `X_test`, `y_train`, and `y_test`. Select 80% of the data for training and 20% for testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this lab, we will try two different models and compare our results.\n",
    "\n",
    "The first model we will use in this lab is logistic regression. We have previously learned about logistic regression as a classification algorithm. In the cell below, load `LogisticRegression` from scikit-learn and initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, fit the model to our training data. We have already separated our data into 4 parts. Use those in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, import `confusion_matrix` and `accuracy_score` from `sklearn.metrics` and fit our testing data. Assign the fitted data to `y_pred` and print the confusion matrix as well as the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are your thoughts on the performance of the model? Write your conclusions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your conclusions here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our second algorithm is is K-Nearest Neighbors. \n",
    "\n",
    "Though is it not required, we will fit a model using the training data and then test the performance of the model using the testing data. Start by loading `KNeighborsClassifier` from scikit-learn and then initializing and fitting the model. We'll start off with a model where k=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your model, compute the predicted values for the testing sample and print the confusion matrix as well as the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll create another K-Nearest Neighbors model with k=5. \n",
    "\n",
    "Initialize and fit the model below and print the confusion matrix and the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you see an improvement in the confusion matrix when increasing k to 5? Did you see an improvement in the accuracy score? Write your conclusions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your conclusions here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Feature Scaling\n",
    "\n",
    "Problem-solving in machine learning is iterative. You can improve your model prediction with various techniques (there is a sweetspot for the time you spend and the improvement you receive though). Now you've completed only one iteration of ML analysis. There are more iterations you can conduct to make improvements. In order to be able to do that, you will need deeper knowledge in statistics and master more data analysis techniques. In this bootcamp, we don't have time to achieve that advanced goal. But you will make constant efforts after the bootcamp to eventually get there.\n",
    "\n",
    "However, now we do want you to learn one of the advanced techniques which is called *feature scaling*. The idea of feature scaling is to standardize/normalize the range of independent variables or features of the data. This can make the outliers more apparent so that you can remove them. This step needs to happen during Challenge 6 after you split the training and test data because you don't want to split the data again which makes it impossible to compare your results with and without feature scaling. For general concepts about feature scaling, click [here](https://en.wikipedia.org/wiki/Feature_scaling). To read deeper, click [here](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e).\n",
    "\n",
    "In the next cell, attempt to improve your model prediction accuracy by means of feature scaling. A library you can utilize is `sklearn.preprocessing.RobustScaler` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)). You'll use the `RobustScaler` to fit and transform your `X_train`, then transform `X_test`. You will use logistic regression to fit and predict your transformed data and obtain the accuracy score in the same way. Compare the accuracy score with your normalized data with the previous accuracy data. Is there an improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-sklearn_env]",
   "language": "python",
   "name": "conda-env-.conda-sklearn_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
